{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd08385ea9c1b89c046143ed892d3a6417099bb117058907eb25ccd44462e08e108",
   "display_name": "Python 3.8.5 64-bit ('hawking': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "## Transfer annotated data to cvat_annotation\n",
    "\n",
    "* Removes images with no annotations\n",
    "* Combines multiple annotation folders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"gas_cylinder\"\n",
    "data_dirs = [\n",
    "    Path(r\"C:\\Users\\Admin\\Downloads\") / sub_dir\n",
    "    for sub_dir in (\n",
    "        \"task_label food_stall_gas_cylinder-2021_05_19_05_39_58-yolo 1.1\",\n",
    "        \"task_label gas_cylinder_peddler-2021_05_19_09_36_37-yolo 1.1\",\n",
    "        \"task_label gas_cylinder_street_vendor-2021_05_19_04_58_51-yolo 1.1\",\n",
    "        \"task_label roadside_food_stall_gas_cylinder-2021_05_19_05_47_18-yolo 1.1\",\n",
    "    )\n",
    "]\n",
    "output_dir = Path.cwd().parents[1] / \"cvat_annotation\" / class_name\n",
    "data_split_dir = output_dir / \"data_split\"\n",
    "train_dir = data_split_dir / \"train\"\n",
    "test_dir = data_split_dir / \"test\"\n",
    "train_images_dir = train_dir / \"images\"\n",
    "train_labels_dir = train_dir / \"labels\"\n",
    "test_images_dir = test_dir / \"images\"\n",
    "test_labels_dir = test_dir / \"labels\"\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "train_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "train_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "test_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "test_labels_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all to jpg\n",
    "for data_dir in data_dirs:\n",
    "    for path in (data_dir / \"obj_train_data\").glob(\"*.png\"):\n",
    "        im = Image.open(path)\n",
    "        im.convert(\"RGB\").save(path.with_suffix(\".jpg\"), \"JPEG\")\n",
    "        os.remove(path)\n",
    "\n",
    "count = 0\n",
    "for data_dir in data_dirs:\n",
    "    for path in (data_dir / \"obj_train_data\").glob(\"*.jpg\"):\n",
    "        shutil.copy(path, output_dir / f\"{class_name}_scraped_{count}.jpg\")\n",
    "        shutil.copy(path.with_suffix(\".txt\"), output_dir / f\"{class_name}_scraped_{count}.txt\")\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "image_list = list(output_dir.glob(\"*.jpg\"))\n",
    "image_train, image_test = train_test_split(image_list, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in image_train:\n",
    "    shutil.copy(path, train_images_dir / path.name)\n",
    "    shutil.copy(path.with_suffix(\".txt\"), train_labels_dir / f\"{path.stem}.txt\")\n",
    "\n",
    "for path in image_test:\n",
    "    shutil.copy(path, test_images_dir / path.name)\n",
    "    shutil.copy(path.with_suffix(\".txt\"), test_labels_dir / f\"{path.stem}.txt\")"
   ]
  },
  {
   "source": [
    "## Transfer from syndata to oidv6_data_converted\n",
    "\n",
    "Single class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"gas_cylinder\"\n",
    "\n",
    "data_dir = Path.cwd().parent / \"hawking_output_dir\"\n",
    "output_dir = Path.cwd().parents[1] / f\"oidv6_data_converted_{class_name}\"\n",
    "output_image_dir = output_dir / \"images\"\n",
    "output_label_dir = output_dir / \"labels\"\n",
    "\n",
    "output_image_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_label_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = \"train\"\n",
    "(output_image_dir / subset).mkdir(parents=True, exist_ok=True)\n",
    "(output_label_dir / subset).mkdir(parents=True, exist_ok=True)\n",
    "for path in (data_dir / \"images\").glob(\"*.jpg\"):\n",
    "    path_stem = path.stem\n",
    "    shutil.copy(path, output_image_dir / subset / f\"{class_name}_{path_stem}.jpg\")\n",
    "    with open(data_dir / \"annotations\" / f\"{path_stem.split('_')[0]}.txt\", \"r\") as infile, open(\n",
    "        output_label_dir / subset / f\"{class_name}_{path_stem}.txt\", \"w\"\n",
    "    ) as outfile:\n",
    "        l = [x.split() for x in infile.read().strip().splitlines()]\n",
    "        for line_parts in np.unique(l, axis=0):\n",
    "            outfile.write(\n",
    "                f\"0 {' '.join(line_parts[1:])}\\n\"\n",
    "            )"
   ]
  },
  {
   "source": [
    "## Transfer from cvat annotated to oidv6_data_converted\n",
    "\n",
    "Single class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"gas_cylinder\"\n",
    "\n",
    "data_dir = Path.cwd().parents[1] / \"cvat_annotation\"\n",
    "output_dir = Path.cwd().parents[1] / f\"oidv6_data_converted_{class_name}\"\n",
    "output_image_dir = output_dir / \"images\"\n",
    "output_label_dir = output_dir / \"labels\"\n",
    "\n",
    "output_image_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_label_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in (\"train\", \"test\"):\n",
    "    (output_image_dir / subset).mkdir(parents=True, exist_ok=True)\n",
    "    (output_label_dir / subset).mkdir(parents=True, exist_ok=True)\n",
    "    for path in (data_dir / class_name / \"data_split\" / subset / \"images\").glob(\"*.jpg\"):\n",
    "        shutil.copy(path, output_image_dir / subset / path.name)\n",
    "        shutil.copy(\n",
    "            path.parents[1] / \"labels\" / f\"{path.stem}.txt\",\n",
    "            output_label_dir / subset / f\"{path.stem}.txt\",\n",
    "        )"
   ]
  },
  {
   "source": [
    "## Transfer from single class oidv6_data_converted to multiclass oidv6_data_converted\n",
    "Includes relabeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"gas_cylinder\"\n",
    "classes = [\"apple\", \"banana\", \"orange\", \"wheelchair\", \"wok\", \"box\", \"table\", \"tissue\", \"gas_cylinder\"]\n",
    "\n",
    "data_dir = Path.cwd().parents[1] / f\"oidv6_data_converted_{class_name}\"\n",
    "output_dir = Path.cwd().parents[1] / f\"oidv6_data_converted_9classes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in (\"train\", \"test\"):\n",
    "    for path in (data_dir / \"images\" / subset).glob(\"*.jpg\"):\n",
    "        shutil.copy(path, output_dir / \"images\" / subset / path.name)\n",
    "        with open(data_dir / \"labels\" / subset / f\"{path.stem}.txt\", \"r\") as infile, open(\n",
    "            output_dir / \"labels\" / subset / f\"{path.stem}.txt\", \"w\"\n",
    "        ) as outfile:\n",
    "            l = [x.split() for x in infile.read().strip().splitlines()]\n",
    "            for line_parts in np.unique(l, axis=0):\n",
    "                outfile.write(\n",
    "                    f\"{classes.index(class_name)} {' '.join(line_parts[1:])}\\n\"\n",
    "                )"
   ]
  },
  {
   "source": [
    "## Legacy functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent / \"oidv6_data\" / \"multidata\"\n",
    "output_dir = Path.cwd().parent / \"oidv6_data_converted_7classes\"\n",
    "\n",
    "classes = [\"apple\", \"banana\", \"orange\", \"wheelchair\", \"wok\", \"box\", \"table\"]\n",
    "old_class_name = \"kitchen_&_dining_room_table\"\n",
    "class_name = \"table\"\n",
    "\n",
    "for path in (data_dir / \"test\").glob(\"*.jpg\"):\n",
    "    shutil.copy(path, output_dir / \"images\" / \"test\" / f\"{class_name}{path.name[len(old_class_name):]}\")\n",
    "    with open(data_dir / \"test\" / \"labels\" / f\"{path.stem}.txt\", \"r\") as infile, open(\n",
    "        output_dir / \"labels\" / \"test\" / f\"{class_name}{path.stem[len(old_class_name):]}.txt\", \"w\"\n",
    "    ) as outfile:\n",
    "        l = [x.split() for x in infile.read().strip().splitlines()]\n",
    "        for line_parts in np.unique(l, axis=0):\n",
    "            outfile.write(\n",
    "                f\"{classes.index(class_name)} {' '.join(line_parts[1:])}\\n\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent / \"oidv6_data_converted_7classes\"\n",
    "class_name = \"table\"\n",
    "subset = \"test\"\n",
    "for path in (data_dir / \"images\" / subset).glob(\"*.jpg\"):\n",
    "    if f\"{class_name}_\" in path.name and len(path.stem) > len(\"table_999_poisson\"):\n",
    "        curr_image = cv2.imread(str(path))\n",
    "        with open(data_dir / \"labels\" / subset / f\"{path.stem}.txt\", \"r+\") as file:\n",
    "            l = [x.split() for x in file.read().strip().splitlines()]\n",
    "            file.seek(0)\n",
    "            for line_parts in np.unique(l, axis=0):\n",
    "                x_min, y_min, x_max, y_max = map(float, line_parts[1:])\n",
    "                file.write(\n",
    "                    f\"{line_parts[0]} \"\n",
    "                    f\"{(x_min + x_max) / 2 / curr_image.shape[1]} \"\n",
    "                    f\"{(y_min + y_max) / 2 / curr_image.shape[0]} \"\n",
    "                    f\"{(x_max - x_min) / curr_image.shape[1]} \"\n",
    "                    f\"{(y_max - y_min) / curr_image.shape[0]}\\n\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"table\"]\n",
    "data_dir = Path.cwd() / \"hawking_output_dir\"\n",
    "# data_dir = Path.cwd().parent / \"oidv6_data_converted_boxes\"\n",
    "# output_dir = Path.cwd().parent / \"oidv6_data_converted_apple_banana_orange_wheelchair_wok_box\"\n",
    "output_dir = Path.cwd().parent / \"oidv6_data_converted_7classes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"table\"\n",
    "for path in (data_dir / \"images\").glob(\"*.jpg\"):\n",
    "    shutil.copy(path, output_dir / \"images\" / \"train\" / f\"{class_name}_{path.name}\")\n",
    "    with open(data_dir / \"annotations\" / f\"{path.stem.split('_')[0]}.txt\", \"r\") as infile, open(\n",
    "        output_dir / \"labels\" / \"train\" / f\"{class_name}_{path.stem}.txt\", \"w\"\n",
    "    ) as outfile:\n",
    "        l = [x.split() for x in infile.read().strip().splitlines()]\n",
    "        for line_parts in np.unique(l, axis=0):\n",
    "            outfile.write(\n",
    "                f\"0 \"\n",
    "                f\"{' '.join(line_parts[1:])}\\n\"\n",
    "            )"
   ]
  },
  {
   "source": [
    "## Relabel class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_file in (output_dir / \"labels\" / \"train\").glob(\"*.txt\"):\n",
    "    with open(label_file, \"r+\") as file:\n",
    "        l = [x.split() for x in file.read().strip().splitlines()]\n",
    "        file.seek(0)\n",
    "        for line_parts in np.unique(l, axis=0):\n",
    "            file.write(f\"0 {' '.join(line_parts[1:])}\\n\")\n",
    "\n",
    "for label_file in (output_dir / \"labels\" / \"test\").glob(\"*.txt\"):\n",
    "    with open(label_file, \"r+\") as file:\n",
    "        l = [x.split() for x in file.read().strip().splitlines()]\n",
    "        file.seek(0)\n",
    "        for line_parts in np.unique(l, axis=0):\n",
    "            file.write(f\"0 {' '.join(line_parts[1:])}\\n\")"
   ]
  },
  {
   "source": [
    "## Combine Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"wok\"\n",
    "for path in (data_dir / \"images\" / \"train\").glob(\"*.jpg\"):\n",
    "    shutil.copy(path, output_dir / \"images\" / \"train\" / f\"{class_name}_{path.name}\")\n",
    "    with open(data_dir / \"labels\" / \"train\" / f\"{path.stem}.txt\", \"r\") as infile, open(\n",
    "        output_dir / \"labels\" / \"train\" / f\"{class_name}_{path.stem}.txt\", \"w\"\n",
    "    ) as outfile:\n",
    "        l = [x.split() for x in infile.read().strip().splitlines()]\n",
    "        for line_parts in np.unique(l, axis=0):\n",
    "            outfile.write(f\"1 {' '.join(line_parts[1:])}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in (data_dir / \"images\" / \"test\").glob(\"*.jpg\"):\n",
    "    shutil.copy(path, output_dir / \"images\" / \"test\" / f\"{class_name}_{path.name}\")\n",
    "    with open(data_dir / \"labels\" / \"test\" / f\"{path.stem}.txt\", \"r\") as infile, open(\n",
    "        output_dir / \"labels\" / \"test\" / f\"{class_name}_{path.stem}.txt\", \"w\"\n",
    "    ) as outfile:\n",
    "        l = [x.split() for x in infile.read().strip().splitlines()]\n",
    "        for line_parts in np.unique(l, axis=0):\n",
    "            outfile.write(f\"1 {' '.join(line_parts[1:])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"apple\", \"banana\", \"orange\", \"wheelchair\", \"wok\", \"box\", \"table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"box\"\n",
    "subset = \"train\"\n",
    "for path in (data_dir / \"images\" / subset).glob(\"*.jpg\"):\n",
    "    shutil.copy(path, output_dir / \"images\" / subset / f\"{class_name}_{path.name}\")\n",
    "    with open(data_dir / \"labels\" / subset / f\"{path.stem}.txt\", \"r\") as infile, open(\n",
    "        output_dir / \"labels\" / subset / f\"{class_name}_{path.stem}.txt\", \"w\"\n",
    "    ) as outfile:\n",
    "        l = [x.split() for x in infile.read().strip().splitlines()]\n",
    "        for line_parts in np.unique(l, axis=0):\n",
    "            outfile.write(f\"{classes.index(class_name)} {' '.join(line_parts[1:])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = \"test\"\n",
    "for path in (data_dir / \"images\" / subset).glob(\"*.jpg\"):\n",
    "    shutil.copy(path, output_dir / \"images\" / subset / f\"{class_name}_{path.name}\")\n",
    "    with open(data_dir / \"labels\" / subset / f\"{path.stem}.txt\", \"r\") as infile, open(\n",
    "        output_dir / \"labels\" / subset / f\"{class_name}_{path.stem}.txt\", \"w\"\n",
    "    ) as outfile:\n",
    "        l = [x.split() for x in infile.read().strip().splitlines()]\n",
    "        for line_parts in np.unique(l, axis=0):\n",
    "            outfile.write(f\"{classes.index(class_name)} {' '.join(line_parts[1:])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent / \"oidv6_data_converted_table\"\n",
    "class_name = \"table\"\n",
    "subset = \"train\"\n",
    "for path in (data_dir / \"images\" / subset).glob(\"*.jpg\"):\n",
    "    if \"{class_name}_\" not in path.name:\n",
    "        shutil.copy(path, output_dir / \"images\" / subset / f\"{class_name}_{path.name}\")\n",
    "        with open(data_dir / \"labels\" / subset / f\"{path.stem}.txt\", \"r\") as infile, open(\n",
    "            output_dir / \"labels\" / subset / f\"{class_name}_{path.stem}.txt\", \"w\"\n",
    "        ) as outfile:\n",
    "            l = [x.split() for x in infile.read().strip().splitlines()]\n",
    "            for line_parts in np.unique(l, axis=0):\n",
    "                outfile.write(f\"{classes.index(class_name)} {' '.join(line_parts[1:])}\\n\")\n",
    "    else:\n",
    "        shutil.copy(path, output_dir / \"images\" / subset / path.name)\n",
    "        with open(data_dir / \"labels\" / subset / f\"{path.stem}.txt\", \"r\") as infile, open(\n",
    "            output_dir / \"labels\" / subset / f\"{path.stem}.txt\", \"w\"\n",
    "        ) as outfile:\n",
    "            l = [x.split() for x in infile.read().strip().splitlines()]\n",
    "            for line_parts in np.unique(l, axis=0):\n",
    "                outfile.write(f\"{classes.index(class_name)} {' '.join(line_parts[1:])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent / \"oidv6_data_converted_table\"\n",
    "class_name = \"table\"\n",
    "subset = \"test\"\n",
    "for path in (data_dir / \"images\" / subset).glob(\"*.jpg\"):\n",
    "    if \"{class_name}_\" not in path.name:\n",
    "        shutil.copy(path, output_dir / \"images\" / subset / f\"{class_name}_{path.name}\")\n",
    "        with open(data_dir / \"labels\" / subset / f\"{path.stem}.txt\", \"r\") as infile, open(\n",
    "            output_dir / \"labels\" / subset / f\"{class_name}_{path.stem}.txt\", \"w\"\n",
    "        ) as outfile:\n",
    "            l = [x.split() for x in infile.read().strip().splitlines()]\n",
    "            for line_parts in np.unique(l, axis=0):\n",
    "                outfile.write(f\"{classes.index(class_name)} {' '.join(line_parts[1:])}\\n\")\n",
    "    else:\n",
    "        shutil.copy(path, output_dir / \"images\" / subset / path.name)\n",
    "        with open(data_dir / \"labels\" / subset / f\"{path.stem}.txt\", \"r\") as infile, open(\n",
    "            output_dir / \"labels\" / subset / f\"{path.stem}.txt\", \"w\"\n",
    "        ) as outfile:\n",
    "            l = [x.split() for x in infile.read().strip().splitlines()]\n",
    "            for line_parts in np.unique(l, axis=0):\n",
    "                outfile.write(f\"{classes.index(class_name)} {' '.join(line_parts[1:])}\\n\")"
   ]
  }
 ]
}